
<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta content="IE=7.0000" http-equiv="X-UA-Compatible">
<title>Liqiang Jing's Homepage</title>
<meta name="description" content="Liqian Jing.">
<meta name="keywords" content="Liqiang Jing, HFUT, SDU, homepage, Master">

<style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style>	
	
<link rel="stylesheet" type="text/css" href="./files/weiyinwei.css">
<meta name="google-site-verification" content="OU-xCmiAYHXy1Aj5mcXXaFv9VjXH0fn1X__CmSR6dUg" />

</head>


<body>
<div id="content">
<!-- ============================NEWS===========================================!-->
<div id="news">
    <h2>News</h2><br>
    <font size="3px">
    
	    
    <b>30 July 2022</b><br>
    <span class="easylink">
    Our paper <b>"Debiased Outfit Compatibility Modeling with Counterfactual"</b> is accepted by <a href="https://mcfr-mm22.github.io/" target="_blank">the Workshop MCFR of ACM MM 2022</a>.
    </span><br><br>
	    
    <b>30 June 2022</b><br>
    <span class="easylink">
    Our full paper <b>"Counterfactual Reasoning for Out-of-distribution Multimodal Sentiment Analysis"</b> is accepted by <a href="https://2022.acmmm.org/" target="_blank">ACM MM 2022</a>.
    </span><br><br>
	    
    <b>28 April 2022</b><br>
    <span class="easylink">
    I won the <a href="https://sigir.org/sigir2022/" target="_blank">ACM SIGIR 2022</a> Student Travel Grant.
    </span><br><br>
	    
    <b>31 March 2022</b><br>
    <span class="easylink">
    Our full paper <b>"V2P: Vision-to-Prompt based Multi-Modal Product Summary Generation"</b> is accepted by <a href="https://sigir.org/sigir2022/" target="_blank">ACM SIGIR 2022</a>.
    </span><br><br>
	    
   <b>1 August 2021</b><br>
    <span class="easylink">
    I will be as a Research Intern at Alibaba DAMO Academy in Aug. 2021, supervised by Zhongzhou Zhao 
    </span><br><br>	    
    </font>
</div>
<!-- ============================Profiles===========================================!-->
<div id="left">
<table style="background-color:white;">
<tbody><tr nosave="">
<td valign="CENTER">
<!--<img src="./images/profile.png" height="220" align="left">-->
<img src="./images/jingliqiang.jpg" height="220" align="left">
</td>

<td valign="CENTER" align="left">
<font size="+0">
<b><font size="+2">Liqiang Jing&nbsp;</font></b>
<p style="margin-left:0px;">
</p><p style="margin-left:0px;">
<!--<b>PHD Student</b>
</p><p style="margin-left:0px;">-->
<a href="http://ilearn.qd.sdu.edu.cn/", target="_blank">iLEARN</a><br/>
<a href="https://www.en.sdu.edu.cn/", target="_blank">Shandong University</a><br/>
<!-- </p><p style="margin-left:0px;">
The Hong Kong Polytechnic University, Hong Kong<br> -->
</p><p style="margin-left:0px;">
Email:&nbsp; jingliqiang6 AT gmail.com</a><br>
<!--&bull; <a href="files/CV_liyongqi0.pdf">CV</a>!--> &bull; <a href="https://scholar.google.com/citations?hl=en&user=aNXRSOsAAAAJ">Google Scholar</a> &bull; <a href="https://github.com/LiqiangJing">GitHub</a> <br>
</p></font><p><font size="+0">
</font>
</p></td>
</tr>
</tbody></table>

<div style="margin-top:20px;">
Liqiang Jing is a graduate student with the School of Computer Science and Technology, Shandong University. 
He received the B.E. degree in School of Computer Science and Technology from Hefei University of Technology, 
Anhui, in 2020. His research interests include multimodal learning and natural language processing.
	
</div>
<!-- ============================Profiles===========================================!-->




<!-- ============================Education===========================================!-->
<h2 style="CLEAR: both;">Education</h2>
<table>
  <tbody>
  <tr>
    <td><span class="title">Shandong University </span> <br>
	Master in Computer Technology, Sep. 2020 -- <br>
	Advisor: <a href="https://xuemengsong.github.io/" target="_blank">A/Prof. Xuemeng Song</a>
     </td>
   </tr>
   </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td><span class="title">Hefei University of Technology </span> <br>
	Bachelor in Computer Science and Technology, Sep. 2016 - Jul. 2020 <br>
     </td>
   </tr>
   </tbody>
</table>


<!-- ============================Experiences===========================================!-->
<h2 style="CLEAR: both">Experiences</h2>
<table>
  <tbody><tr>
    <td> <span class="title">Research Intern</span>, Alibaba DAMO Academy, Aug. 2021 --<br>
			Advisior: Zhongzhou Zhao
		</td></tr></tbody>
</table>
<!-- ============================Experiences===========================================!-->


<!-- ============================Papers===========================================!-->
<div id="papers">
<h2 style="CLEAR: both">Publications <a href="" target="_blank"></a></h2> 
</br>
<b> In the Year of 2022: </b> </br></br>
<table>
  <tbody>
	  
   <tr>
	   <td class="left"><a href="" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Debiased Outfit Compatibility Modeling with Counterfactual</span> 
      <br> <b>Liqiang Jing</b>, Minghui Tian, Xiaolin Chen, Teng Sun, Weili Guan & Xuemeng Song
    <br>MCFR of ACM MM Conference 2022 (Workshop)
   &nbsp;&nbsp;&bull; <a href="https://github.com/LiqiangJing/CI-OCM" target="_blank">Codes&Data</a> &nbsp;&nbsp;
  </td>
  </tr>
	  
  <tr>
	      <td class="left"><a href="https://arxiv.org/pdf/2207.11652.pdf" 
			target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Counterfactual Reasoning for Out-of-distribution Multimodal Sentiment Analysis</span> 
      <br> Teng Sun, Wenjie Wang, <b>Liqiang Jing</b>, Yiran Cui, Xuemeng Song & Liqiang Nie
    <br>ACM MM Conference 2022 (Oral)
   &nbsp;&nbsp;&bull; <a href="https://github.com/Teng-Sun/CLUE_model" target="_blank">Codes&Data</a> &nbsp;&nbsp;
  </td>
  </tr>

  <tr>    
    <td class="left"><a href="https://dl.acm.org/doi/pdf/10.1145/3477495.3532076" 
			target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">V2P: Vision-to-Prompt based Multi-Modal Product Summary Generation</span> 
      <br> Xuemeng Song, <b>Liqiang Jing</b>, Dengtian Lin, Zhongzhou Zhao, Wei Zhou & Liqiang Nie
    <br>ACM SIGIR Conference 2022 (Oral)
   &nbsp;&nbsp;&bull; <a href="https://xuemengsong.github.io/V2P_Code.rar" target="_blank">Codes&Data</a> &nbsp;&nbsp;

  </td>
  </tr>
 </tbody>
</table>

<div id="papers">
<h2 style="CLEAR: both">Preprints <a href="" target="_blank"></a></h2> 
<table>
  <tbody>
<tr>
	      <td class="left"><a href="https://arxiv.org/pdf/2207.07934.pdf" 
			target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Multimodal Dialog Systems with Dual Knowledge-enhanced Generative Pretrained Language Model.</span> 
      <br>Xiaolin Chen, Xuemeng Song,<b>Liqiang Jing</b>, Shuo Li, Linmei Hu & Liqiang Nie
    <br>CoRR abs/2207.07934 2022
   &nbsp;&nbsp;&bull; <a href="https://multimodaldialog.wixsite.com/website" target="_blank">Codes&Data</a> &nbsp;&nbsp;
  </td>
	  </tr>
    

 </tbody>
</table>

<!-- ============================Patent===========================================!-->
<!-- <h2 style="CLEAR: both;">Patent</h2> -->


<!-- ============================Patent===========================================!-->


<!-- ============================Honors===========================================!-->
<h2 style="CLEAR: both;">Honors</h2>
<table><tbody><tr><td>
	
  <span class="title">ACM SIGIR Student Travel Grant, 2022</span><br><br>

  <span class="title">Excellent Graduate, Hefei University of Technology, 2020</span><br><br>

  <span class="title">National Encouragement Scholarship, 2017, 2018, 2019</span><br><br>

  <span class="title">First Class Scholarship, Hefei University of Technology, 2018, 2019</span><br><br>


</td></tr></tbody></table>
	
<h2 style="CLEAR: both;">Presentations</h2>
<table>
  <tbody>
  <tr>
    <td><span class="title">SIGIR 2022 Oral on V2P: Vision-to-Prompt based Multi-Modal Product Summary Generation</span> <br><br>
	<a href="slides/v2p_s.pdf" target="_blank">Slides</a>
     </td>
   </tr>
   </tbody>
</table>
	

<!-- ============================Honors===========================================!-->
<h2 style="CLEAR: both;">Professional Services</h2>

<table><tbody>
	<tr><td>
	<b>Reviwer: ACM MM MCFR 2022, NeurIPS 2022.</b>
	</td></tr>
</tbody></table>

<!-- ============================Invited Talks===========================================!-->




<!-- ============================Invited Talks===========================================!-->
</br>		

<!-- ============================Map===========================================!-->


<!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=tt&d=P5t3EabrzZY8aFh3ZhuRPAXXUh7jCpV3TVHKUlqbMjA&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script> -->
<!-- ============================Map===========================================!-->

<!-- </br>		 -->
<!-- <p>Webpage template borrows from <a href="https://LiqiangJing.github.io/">Liqiang Jing</a>.</p> -->
</div>
</div>

</body></html>
