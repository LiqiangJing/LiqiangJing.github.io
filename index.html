
<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta content="IE=7.0000" http-equiv="X-UA-Compatible">
<title>Liqiang Jing's Homepage</title>
<meta name="description" content="Liqian Jing.">
<meta name="keywords" content="Liqiang Jing, HFUT, SDU, homepage, Master">

<style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style>	
	
<link rel="stylesheet" type="text/css" href="./files/weiyinwei.css">
<meta name="google-site-verification" content="OU-xCmiAYHXy1Aj5mcXXaFv9VjXH0fn1X__CmSR6dUg" />

</head>


<body>
<div id="content">
<!-- ============================NEWS===========================================!-->
<div id="news">
    <h2>News</h2><br>
    <font size="3px">
   
    <b>30 August 2022</b><br>
    <span class="easylink">
    Our paper <b>"Vision Enhanced Generative Pre-trained Language Model for Multimodal Sentence Summarization"</b> is accepted by <a href="https://www.mi-research.net/" target="_blank">Machine Intelligence Research</a>.
    </span><br><br>
	    
    <b>30 July 2022</b><br>
    <span class="easylink">
    Our full paper <b>"CI-OCM: Counterfactural Inference towards Unbiased Outfit Compatibility Modeling"</b> is accepted by <a href="https://mcfr-mm22.github.io/" target="_blank">the Workshop MCFR of ACM MM 2022</a>.
    </span><br><br>
	    
    <b>30 June 2022</b><br>
    <span class="easylink">
    Our full paper <b>"Counterfactual Reasoning for Out-of-distribution Multimodal Sentiment Analysis"</b> is accepted by <a href="https://2022.acmmm.org/" target="_blank">ACM MM 2022</a>.
    </span><br><br>
	    
    <b>28 April 2022</b><br>
    <span class="easylink">
    I won the <a href="https://sigir.org/sigir2022/" target="_blank">ACM SIGIR 2022</a> Student Travel Grant.
    </span><br><br>
	    
    <b>31 March 2022</b><br>
    <span class="easylink">
    Our full paper <b>"V2P: Vision-to-Prompt based Multi-Modal Product Summary Generation"</b> is accepted by <a href="https://sigir.org/sigir2022/" target="_blank">ACM SIGIR 2022</a>.
    </span><br><br>
	    
   <b>1 August 2021</b><br>
    <span class="easylink">
    I will be as a Research Intern at Alibaba DAMO Academy in Aug. 2021, supervised by Zhongzhou Zhao 
    </span><br><br>	    
    </font>
</div>
<!-- ============================Profiles===========================================!-->
<div id="left">
<table style="background-color:white;">
<tbody><tr nosave="">
<td valign="CENTER">
<!--<img src="./images/profile.png" height="220" align="left">-->
<img src="./images/jingliqiang.jpg" height="220" align="left">
</td>

<td valign="CENTER" align="left">
<font size="+0">
<b><font size="+2">Liqiang Jing （井立强）&nbsp;</font></b>
<p style="margin-left:0px;">
</p><p style="margin-left:0px;">
<!--<b>PHD Student</b>
</p><p style="margin-left:0px;">-->
<a href="http://ilearn.qd.sdu.edu.cn/", target="_blank">iLEARN</a><br/>
<a href="https://www.en.sdu.edu.cn/", target="_blank">Shandong University</a><br/>
<!-- </p><p style="margin-left:0px;">
The Hong Kong Polytechnic University, Hong Kong<br> -->
</p><p style="margin-left:0px;">
Email:&nbsp; jingliqiang6 AT gmail.com</a><br>
&bull; <a href="files/CV.pdf">CV</a> &bull; <a href="https://scholar.google.com/citations?hl=en&user=aNXRSOsAAAAJ">Google Scholar</a> &bull; <a href="https://github.com/LiqiangJing">GitHub</a> <br>
</p></font><p><font size="+0">
</font>
</p></td>
</tr>
</tbody></table>

<div style="margin-top:20px;">
Liqiang Jing is a graduate student with the School of Computer Science and Technology, Shandong University. 
He received the B.E. degree in School of Computer Science and Technology from Hefei University of Technology, 
Anhui, in 2020. His research interests include multimodal learning and natural language processing.
	
</div>
<!-- ============================Profiles===========================================!-->




<!-- ============================Education===========================================!-->
<h2 style="CLEAR: both;">Education</h2>
<table>
  <tbody>
  <tr>
    <td><span class="title">Shandong University </span> <br>
	Master in Computer Technology, Sep. 2020 - Present  <br>
	 <a href="papers/trans1.pdf" target="_blank">Transcript</a>  <br>
	Advisor: <a href="https://xuemengsong.github.io/" target="_blank">Xuemeng Song</a> <br>
	Co-Advisor: <a href="https://liqiangnie.github.io/index.html" target="_blank">Liqiang Nie</a> 
     </td>
   </tr>
   </tbody>
</table>     

<table>
  <tbody>
  <tr>
    <td><span class="title">Hefei University of Technology </span> <br>
	Bachelor in Computer Science and Technology, Sep. 2016 - Jul. 2020 <br>
	    <a href="papers/trans2.pdf" target="_blank">Transcript</a> <br>
     </td>
   </tr>
   </tbody>
</table>


<!-- ============================Experiences===========================================!-->
<h2 style="CLEAR: both">Experiences</h2>
<table>
  <tbody><tr>
    <td> <span class="title">Research Intern</span>, Alibaba DAMO Academy, May. 2022 -- <br>
			Advisior:  <a href="https://dblp.uni-trier.de/pid/207/9948.html" target="_blank">Zhongzhou Zhao</a>
		</td></tr></tbody>
</table>

<table>
  <tbody><tr>
    <td> <span class="title">AIR <a href="https://damo.alibaba.com/collaborations/?tab=0" target="_blank">(Alibaba Innovative Research)</a> Project Intern</span>, Alibaba DAMO Academy, Aug. 2021 -- Jan. 2022 <br>
			Advisior:  <a href="https://dblp.uni-trier.de/pid/207/9948.html" target="_blank">Zhongzhou Zhao</a>
		</td></tr></tbody>
</table>



<!-- ============================Experiences===========================================!-->


<!-- ============================Papers===========================================!-->
<div id="papers">
<h2 style="CLEAR: both">Publications <a href="" target="_blank"></a></h2> 
</br>
<b> In the Year of 2022: </b> </br></br>
<table>
  <tbody>  
  <tr>    
    <td class="left"><a href="papers/v2p.pdf" 
			target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">V2P: Vision-to-Prompt based Multi-Modal Product Summary Generation</span> 
      <br> Xuemeng Song, <b>Liqiang Jing</b>, Dengtian Lin, Zhongzhou Zhao, Haiqing Chen & Liqiang Nie
    <br>ACM SIGIR Conference 2022 (Oral)
   &nbsp;&nbsp;&bull; <a href="https://xuemengsong.github.io/V2P_Code.rar" target="_blank">Codes&Data</a> &nbsp;&nbsp;

  </td>
  </tr>
	 
	    <tr>
	      <td class="left"><a href="papers/cr-msa.pdf" 
			target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Counterfactual Reasoning for Out-of-distribution Multimodal Sentiment Analysis</span> 
      <br> Teng Sun, Wenjie Wang, <b>Liqiang Jing</b>, Yiran Cui, Xuemeng Song & Liqiang Nie
    <br>ACM MM Conference 2022 (Oral)
   &nbsp;&nbsp;&bull; <a href="https://github.com/Teng-Sun/CLUE_model" target="_blank">Codes&Data</a> &nbsp;&nbsp;
  </td>
  </tr>
	     <tr>
	   <td class="left"><a href="papers/ocm.pdf" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">CI-OCM: Counterfactural Inference towards Unbiased Outfit Compatibility Modeling</span> 
      <br> <b>Liqiang Jing</b>, Minghui Tian, Xiaolin Chen, Teng Sun, Weili Guan & Xuemeng Song
    <br>MCFR of ACM MM Conference 2022 (Full Paper)
   &nbsp;&nbsp;&bull; <a href="https://github.com/LiqiangJing/CI-OCM" target="_blank">Codes&Data</a> &nbsp;&nbsp;
  </td>
  </tr>
	  <tr>
	      <td class="left"><a href="papers/vision-gplm.pdf" 
			target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Vision Enhanced Generative Pre-trained Language Model for Multimodal Sentence Summarization</span> 
      <br> <b>Liqiang Jing</b>, Yiren Li, Junhao Xu, Yongcan Yu, Peo Shen & Xuemeng Song
    <br>Machine Intelligence Research
   &nbsp;&nbsp;&bull; <a href="https://github.com/LiqiangJing/Vision-GPLM" target="_blank">Codes&Data</a> &nbsp;&nbsp;
  </td>
  </tr>  
 </tbody>
</table>

<div id="papers">
<h2 style="CLEAR: both">Preprints <a href="" target="_blank"></a></h2> 
<table>
  <tbody>
<tr>
	      <td class="left"><a href="papers/dkmd.pdf" 
			target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Multimodal Dialog Systems with Dual Knowledge-enhanced Generative Pretrained Language Model.</span> 
      <br>Xiaolin Chen, Xuemeng Song, <b>Liqiang Jing</b>, Shuo Li, Linmei Hu & Liqiang Nie
    <br>CoRR abs/2207.07934 2022
   &nbsp;&nbsp;&bull; <a href="https://multimodaldialog.wixsite.com/website" target="_blank">Codes&Data</a> &nbsp;&nbsp;
  </td>
	  </tr>
    

 </tbody>
</table>

<!-- ============================Patent===========================================!-->
<!-- <h2 style="CLEAR: both;">Patent</h2> -->







</td></tr></tbody></table>

<h2 style="CLEAR: both;">Presentations</h2>
	
<table><tbody><tr><td>
  <span class="title">ACM SIGIR 2022 Oral on V2P: Vision-to-Prompt based Multi-Modal Product Summary Generation</span> &nbsp;&nbsp; 
  <br> <a href="papers/v2p1.pdf" target="_blank">Slides</a>
</td></tr></tbody></table>

<table><tbody><tr><td>
  <span class="title">ACM MM 2022 Oral on Counterfactual Reasoning for Out-of-distribution Multimodal Sentiment Analysis</span> &nbsp;&nbsp; 
  <br> <a href="papers/msa1.pdf" target="_blank">Slides</a>
</td></tr></tbody></table>
	
<table><tbody><tr><td>
  <span class="title">ACM MCFR 2022 on CI-OCM: Counterfactual Inference towards Unbiased Outfit Compatibility Modeling</span> &nbsp;&nbsp; 
  <br> <a href="papers/ocm1.pdf" target="_blank">Slides</a>
</td></tr></tbody></table>

<!-- ============================Patent===========================================!-->

<h2 style="CLEAR: both;">Patent</h2>

<table><tbody><tr><td>
  <span class="title">A script construction method based on multi-modal summary of commodity details page/一种基于商品详情页多模态摘要的剧本构建方法(applying)&nbsp;&nbsp;
</td></tr></tbody></table>

<table><tbody><tr><td>
  <span class="title"> A logical and style-controlled script generation scheme/一种逻辑与风格可控制的剧本生成方案(applying)&nbsp;&nbsp;
</td></tr></tbody></table>

<table><tbody><tr><td>
  <span class="title">A method for blast furnace gas prediction in iron and steel enterprises based on multi-source data/一种基于多源数据驱动的钢铁企业高炉煤气预测方法(applying)&nbsp;&nbsp;
</td></tr></tbody></table>

<!-- ============================Professional Service===========================================!-->
<h2 style="CLEAR: both;">Professional Services</h2>

<table><tbody>
	<tr><td>
	<b>Invited Reviwer for Conference: ACM MM Workshop 2022, NeurIPS 2022.</b>
	</td></tr>
	<tr><td>
	<b>Invited Reviwer for Journal: Information Sciences.</b>
	</td></tr>
</tbody></table>


<!-- ============================Honors===========================================!-->
<h2 style="CLEAR: both;">Honors</h2>
<table><tbody><tr><td>
	
  <span class="title">ACM SIGIR Student Travel Grant, 2022</span><br><br>

  <span class="title">Excellent Graduate (Top 10%), Hefei University of Technology, 2020</span><br><br>

  <span class="title">National Encouragement Scholarship (Top 3.5%), 2017, 2018, 2019</span><br><br>

  <span class="title">First Class Scholarship (Top 3%), Hefei University of Technology, 2018, 2019</span><br><br>

</tbody></table>
<!-- ============================Invited Talks===========================================!-->
</br>		

<!-- ============================Map===========================================!-->
<a href="https://clustrmaps.com/site/1bpzi"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=vuHwEKQroohZZfj1UB99qZ70x6e6FgHjRjzZ1ukd3I0&cl=ffffff" /></a>
<!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=vuHwEKQroohZZfj1UB99qZ70x6e6FgHjRjzZ1ukd3I0&cl=ffffff&w=a"></script> -->
<!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=tt&d=P5t3EabrzZY8aFh3ZhuRPAXXUh7jCpV3TVHKUlqbMjA&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script> -->
<!-- ============================Map===========================================! -->

<!-- </br>		
<p>Webpage template borrows from <a href="https://weiyinwei.github.io/">Yinwei Wei</a>.</p>
</div>
</div> -->

</body></html>
